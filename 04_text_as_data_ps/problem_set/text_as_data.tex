\documentclass[11pt]{article}
\usepackage{amsmath, amssymb, graphicx, hyperref}
\usepackage{enumitem}
\setlist{nosep}
\usepackage[margin=1in]{geometry}

\title{ Text as Data Pipelines}
\author{ }
\date{ }



\begin{document}
\maketitle

\noindent \textbf{Note on data.} This problem set uses a \textbf{synthetic} text corpus created for the Week code tutorial (or an instructor-provided file). The goal is to practice end-to-end text pipelines---not to make substantive claims about real-world political texts.

\section*{Conceptual Questions}
Please write three to ten sentence explanations for each of the following questions. \textbf{You are only required to answer ONE of the two questions below.} \bigskip
 
\begin{enumerate}

\item Compare \textbf{bag-of-words} representations (e.g., a document-term matrix) to \textbf{embedding} representations (Word2Vec / transformer embeddings). Discuss two trade-offs involving interpretability, robustness, and downstream modeling. Give one concrete example of when you would prefer each representation in social science research.

\item A text-as-data pipeline is more than a model. Describe a practical pipeline architecture for a research project that uses topic models and embeddings. In your answer, address (i) where you would cache intermediate artifacts (e.g., tokenized text, vocabulary, embeddings), (ii) how you would document versions and randomness (seeds), and (iii) one way you would prevent data leakage or overfitting when evaluating models.

  \end{enumerate}


\section*{Applied Exercises}
Use the code in the week's code tutorial and the lecture slides to answer the following questions.\bigskip

  \begin{enumerate}
  \setcounter{enumi}{2}

\item \textbf{Topic model (LDA): tokenization $\rightarrow$ document-term matrix $\rightarrow$ topics.}
Using the Week Python tutorial (classic LDA section):
\begin{itemize}
  \item Load the synthetic corpus (e.g., \texttt{data\_raw/week\_synthetic\_corpus.csv}) and create a document-term matrix using \texttt{CountVectorizer}.
  \item Fit an LDA model with a chosen number of topics (e.g., $K=6$).
  \item Report the top 8--12 words for each topic.
  \item Assign each document a dominant topic and create a plot showing the number of documents per dominant topic.
  \item In 5--8 sentences, interpret at least \textbf{two} topics (what they seem to capture) and explain how preprocessing choices (stopwords, \texttt{min\_df}, token pattern) affect topic quality.
\end{itemize}

\item \textbf{Word embedding regression: Word2Vec $\rightarrow$ document vectors $\rightarrow$ out-of-sample prediction.}
Using the Word2Vec regression section of the tutorial:
\begin{itemize}
  \item Tokenize the documents (simple tokenization is fine).
  \item Train Word2Vec on the corpus and create a document embedding for each document by averaging its word vectors.
  \item Fit a Ridge regression model to predict the provided outcome variable (e.g., \texttt{y\_outcome}). Use a train/test split and report out-of-sample \textbf{MAE}, \textbf{RMSE}, and $R^2$.
  \item Create a predicted-vs-actual scatterplot (or another clear diagnostic plot).
  \item In 5--8 sentences, explain what it means to regress an outcome on embeddings and discuss at least \textbf{two} limitations of this approach (e.g., interpretability, domain shift, embedding quality, small corpora).
\end{itemize}

\item \textbf{BERTopic: transformer embeddings $\rightarrow$ clustering $\rightarrow$ topic summaries.}
Using the BERTopic section of the tutorial:
\begin{itemize}
  \item Fit BERTopic and generate a topic summary table (e.g., \texttt{get\_topic\_info()}).
  \item Create a plot of topic counts (excluding outliers if present).
  \item Report (i) the number of topics discovered (excluding outliers) and (ii) the share of documents assigned to the outlier topic (Topic $=-1$), if applicable.
  \item In 6--10 sentences, compare BERTopic to LDA on this dataset: discuss topic interpretability, sensitivity to preprocessing, and computational cost. Identify one situation where BERTopic is likely to outperform LDA and one where LDA may be preferable.
\end{itemize}

\item \textbf{Challenge Question (Optional --- if you finish early):}
Use \textbf{transformer embeddings} for prediction and compare to Word2Vec regression.
\begin{itemize}
  \item Compute sentence/document embeddings using a lightweight model (e.g., \texttt{sentence-transformers/all-MiniLM-L6-v2}).
  \item Fit a Ridge regression (or another simple model) to predict \texttt{y\_outcome} using the transformer embeddings.
  \item Report MAE, RMSE, and $R^2$, and compare them directly to your Word2Vec regression results.
  \item In 4--8 sentences, interpret why the transformer approach does better or worse here, and what that implies for choosing representations in real text-as-data projects.
\end{itemize}

\end{enumerate}

\end{document}
